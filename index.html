<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Resume</title>
</head>
<body>
    <h1>Nihal V Kanchan</h1>
    <img src="./assets/images/MyPicture-LinkedIn.jpeg" height="200" atl="Nihal's image">
    <hr />

    <h2>Summary</h2>
    <p>
        Highly skilled and results-driven Data Engineer with seven years of experience in designing, developing, and optimizing data pipelines and ETL processes. Proficient in leveraging cutting-edge technologies to facilitate data-driven decision-making and enhance overall business efficiency. Adept at collaborating with cross-functional teams to deliver robust data solutions. Demonstrated expertise in big data processing and cloud-based architectures.
    </p>

    <h2>Education</h2>
    <ul>
        <li><strong>School: </strong>
            <br />
            <a href="https://sphs.vidyavardhakasangha.in/index.php/school">VVS Sardar Patel High School</a> | 2000-2010
        </li>
        <li><strong>Pre-University: </strong>
            <br />
            <a href="https://deekshalearning.com/pu-college-near-mahalakshmipuram-bengaluru/">KMWA PU College</a> | 2010-2012
        </li>
        <li><strong>Under-Graduation: </strong>
            <br />
            <a href="https://www.msrit.edu/">M.S Ramaiah Institute of Technology</a> | 2012-2016
        </li> 
    </ul>

    <h2>Work Experience</h2>
    <ol>
        <li><strong>Data Engineer | Eli Lilly Services India Pvt. Ltd. | Bangalore, Karnataka | 2019 - Present</strong>
            <ul>
                <li>Led the development of a real-time data processing system, reducing data latency and enabling quicker business insights.</li>
                <li>Designed and implemented an ETL pipeline to handle research data (Red/Yellow category data) based upon criticality to meet SLO and increasing data extraction efficiency and enhancing data accuracy.</li>
                <li>Collaborated with computational chemists, biologists and data scientists to implement machine learning models into production, resulting improvement in predictive analytics.</li>
                <li>Implemented data governance policies and data lifecycle management procedures, ensuring compliance with data privacy regulations.</li>
                <li>Designed and implemented a scalable data warehouse using Redshift and Postgres, improving query performance and providing a unified platform for business intelligence and reporting.</li>
                <li>Developed automated data pipelines using Apache Airflow, reducing manual intervention and ensuring seamless data ingestion and processing.</li>
                <li>Developed custom data processing solutions using Java and Hadoop, enabling the analysis of large-scale datasets and facilitating data-driven decision-making.</li>
                <li>Implemented real-time data streaming using Apache Kafka, providing timely insights for operational monitoring and reducing data latency.</li>
                <li>Collaborated with data analysts to design data models for reporting and visualization, enabling more efficient and accurate reporting for business users.</li>
                <li>Conducted data migration and integration projects, ensuring seamless data transfer between systems and maintaining data consistency.</li>
            </ul>
        </li>
        <br />
        <li><strong>Database Administrator | Epsilon India Pvt. Ltd. | Bangalore, Karnataka | 2016 - 2019</strong>
            <ul>
                <li>Administered and optimized multiple IBM Netezza data warehouse environments, ensuring high availability and efficient data processing for business users.</li>
                <li>Conducted database performance tuning, resulting in a 30% reduction in query response time and improved overall system efficiency.</li>
                <li>Implemented backup and recovery strategies, ensuring data integrity and providing disaster recovery solutions for critical systems.</li>
                <li>Collaborated with application developers to design and implement ETL processes, enabling seamless data integration from various sources.</li>
                <li>Conducted regular database maintenance, patching, and upgrades, ensuring system stability and security.</li>
                <li>Managed and maintained AWS Redshift clusters, optimizing data distribution keys and sort keys to enhance query performance.</li>
                <li>Implemented data encryption and access control policies, ensuring compliance with data security and privacy regulations.</li>
                <li>Led the migration of on-premises data warehouses to AWS Redshift, resulting in cost savings and improved scalability.</li>
                <li>Monitored and fine-tuned Redshift performance, identifying and resolving bottlenecks to ensure smooth data processing.</li>
                <li>Provided technical support to data engineering and analytics teams, assisting with query optimization and troubleshooting.</li>
            </ul>
        </li>
        <br />
    </ol>

    <h2>Skills</h2>
    <ul>
        <li><strong>Data Warehousing:</strong> Designing and implementing efficient data warehousing solutions using industry-leading tools (e.g., Amazon Redshift, IBM Netezza, Snowflake).</li>
        <li><strong>ETL Development:</strong> Developing and optimizing ETL workflows for data extraction, transformation, and loading, ensuring data integrity and accuracy using tools such as Apache Airflow.</li>
        <li><strong>Big Data Technologies:</strong> Utilizing Hadoop, Spark, and other big data frameworks to process and analyse large datasets efficiently.</li>
        <li><strong>Cloud Platforms:</strong> Experience working with major cloud platforms (AWS, Azure) to build scalable and cost-effective data solutions.</li>
        <li><strong>Database Management:</strong> Proficient in SQL and NoSQL databases for effective data storage, retrieval, and management.</li>
        <li><strong>Data Modelling:</strong> Designing and implementing logical and physical data models to support business requirements.</li>
        <li><strong>Data Quality Assurance:</strong> Implementing data validation and cleansing processes using latest tools such as Great Expectations to ensure validation, documentation and profiling of the data.</li>
        <li><strong>Programming Languages:</strong> Expertise in Python, C++ or Shell Scripting for scripting and application development.</li>
        <li><strong>Data Visualization:</strong> Creating insightful data visualizations using tools such as Tableau to aid in decision-making.</li>
        <li><strong>Team Collaboration:</strong> Proven ability to work effectively in cross-functional teams and communicate complex technical concepts to non-technical stakeholders.</li>
    </ul>

    <h2>Hobbies</h2>
    <p>My hobbies are listed in the below url.
        <br />
        <a href="./public/hobbies.html">My Hobbies</a>
    </p>

    <h2>Contact</h2>
    <p>Please visit the below url to fetch my contact details.
        <br />
        <a href="./public/contact.html">Contact Information</a>
    </p>

    <footer>
        <small>Copyright Â© 2025 Nihal V Kanchan. All Rights Reserved.</small>
    </footer>

</body>
</html>